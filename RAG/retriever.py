import os
from pathlib import Path

from langchain_chroma import Chroma
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings

# --- åŸºç¡€ä¾èµ– ---
os.environ['HF_HUB_OFFLINE'] = '1'
# --- è·¯å¾„é…ç½® ---
CURRENT_FILE_DIR = Path(__file__).parent.resolve()
PERSIST_DIRECTORY = CURRENT_FILE_DIR / "data" / "chroma_db"


# --- å…¨å±€æ¨¡å‹ç¼“å­˜ (å•ä¾‹æ¨¡å¼) ---
_EMBEDDING_MODEL = None
_VECTOR_DB = None
_RERANKER = None

# --- é…ç½®å‚æ•° ---
RERANK_SCORE_THRESHOLD = 0.5  # é‡æ’åºè¯„åˆ†é˜ˆå€¼ï¼Œä½äºæ­¤åˆ†æ•°çš„æ–‡æ¡£ä¸ä¼šè¿”å›


def get_embedding_model():
    """æ‡’åŠ è½½ Embedding æ¨¡å‹"""
    global _EMBEDDING_MODEL
    if _EMBEDDING_MODEL is None:
        print("   [System] æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹ (BAAI/bge-m3)...")
        _EMBEDDING_MODEL = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={"device": "cpu"},
            encode_kwargs={'normalize_embeddings': True}
        )
    return _EMBEDDING_MODEL


def get_vector_db():
    """æ‡’åŠ è½½ å‘é‡æ•°æ®åº“"""
    global _VECTOR_DB
    if _VECTOR_DB is None:
        if not PERSIST_DIRECTORY.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æœªæ‰¾åˆ°: {PERSIST_DIRECTORY}")
        
        print("   [System] æ­£åœ¨è¿æ¥å‘é‡æ•°æ®åº“...")
        _VECTOR_DB = Chroma(
            persist_directory=str(PERSIST_DIRECTORY),
            embedding_function=get_embedding_model(),
            collection_name="trip_guard_collection"
        )
    return _VECTOR_DB


def get_reranker():
    """æ‡’åŠ è½½ Rerank æ¨¡å‹"""
    global _RERANKER
    if _RERANKER is None:
        print("   [System] æ­£åœ¨åˆå§‹åŒ– Rerank æ¨¡å‹ (BAAI/bge-reranker-base)...")
        _RERANKER = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-base")
    return _RERANKER


def vector_search(query: str, vector_db: Chroma, k: int = 10):
    """
    å‘é‡æ£€ç´¢ (Vector Search) - è¯­ä¹‰å¬å›
    """
    print("   - æ‰§è¡Œå‘é‡æ£€ç´¢...")
    return vector_db.similarity_search(query, k=k)


def bm25_search(query: str, vector_db: Chroma, k: int = 10):
    """
    BM25 æ£€ç´¢ (Keyword Search) - å…³é”®è¯å¬å›
    """
    print("   - æ‰§è¡Œå…³é”®è¯æ£€ç´¢...")
    try:
        # è·å–æ‰€æœ‰æ–‡æ¡£ç”¨äºæ„å»ºç´¢å¼•
        db_data = vector_db.get()
        all_docs = db_data['documents']
        all_metadatas = db_data['metadatas']

        if not all_docs:
            print("   âš ï¸ è­¦å‘Š: æ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡ BM25")
            return []
        
        bm25_docs = [Document(page_content=t, metadata=m) for t, m in zip(all_docs, all_metadatas)]
        bm25_retriever = BM25Retriever.from_documents(bm25_docs)
        bm25_retriever.k = k
        return bm25_retriever.invoke(query)
    except Exception as e:
        print(f"   âš ï¸ BM25 æ„å»ºå¤±è´¥(å¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œæˆ–ä¾èµ–ç¼ºå¤±): {e}")
        return []


def ensemble_results(vector_docs: list, keyword_docs: list):
    """
    æ‰‹åŠ¨å»é‡åˆå¹¶ (Ensemble Logic)
    """
    unique_docs = {}
    # å…ˆæ”¾å…¥å‘é‡ç»“æœï¼Œå†æ”¾å…¥å…³é”®è¯ç»“æœ
    for doc in vector_docs + keyword_docs:
        # ä½¿ç”¨å†…å®¹ä½œä¸ºå»é‡é”® (é˜²æ­¢åŒä¸€æ®µè¯è¢«é‡å¤å¬å›)
        key = doc.page_content.strip()
        if key not in unique_docs:
            unique_docs[key] = doc

    merged_docs = list(unique_docs.values())
    print(f"   - å¬å›åˆå¹¶åæ–‡æ¡£æ•°: {len(merged_docs)}")
    return merged_docs


def rerank_documents(query: str, merged_docs: list, top_k: int = 3, score_threshold: float = 0.5):
    """
    æ‰‹åŠ¨é‡æ’åº (Rerank Logic)
    åªè¿”å›é‡æ’åºå¾—åˆ† >= score_threshold çš„æ–‡æ¡£
    """
    if not merged_docs:
        return []

    print("   - æ‰§è¡Œé‡æ’åº (Rerank)...")
    # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–æ¨¡å‹
    reranker = get_reranker()

    # æ„é€  Pair: [query, doc_content]
    pairs = [(query, doc.page_content) for doc in merged_docs]

    scores = reranker.score(pairs)

    # å°†åˆ†æ•°ç»‘å®šåˆ°æ–‡æ¡£å¹¶æ’åº
    scored_docs = sorted(
        zip(merged_docs, scores),
        key=lambda x: x[1],
        reverse=True
    )

    # å– Top Kï¼Œå¹¶æ ¹æ®é˜ˆå€¼è¿‡æ»¤ï¼Œå°†å¾—åˆ†å­˜å‚¨åˆ°æ–‡æ¡£metadataä¸­
    result_docs = []
    for doc, score in scored_docs[:top_k]:
        # åªä¿ç•™å¾—åˆ† >= score_threshold çš„æ–‡æ¡£
        if score >= score_threshold:
            # åˆ›å»ºæ–°æ–‡æ¡£å‰¯æœ¬ï¼Œæ·»åŠ é‡æ’åºå¾—åˆ†
            new_doc = Document(
                page_content=doc.page_content,
                metadata=doc.metadata.copy() if hasattr(doc, 'metadata') else {}
            )
            new_doc.metadata['rerank_score'] = float(score)
            result_docs.append(new_doc)
    
    print(f"   - è¿‡æ»¤åç¬¦åˆé˜ˆå€¼(>={score_threshold})çš„æ–‡æ¡£æ•°: {len(result_docs)}")
    return result_docs


def get_manual_hybrid_results(query: str):
    """
    æ‰‹åŠ¨æ‰§è¡Œï¼šå‘é‡æ£€ç´¢ + BM25æ£€ç´¢ -> ç®€å•åˆå¹¶ -> Rerank
    """
    print(f"ğŸ” å¼€å§‹æ‰§è¡Œæ··åˆæ£€ç´¢: {query}")

    # 1. è·å–æ¨¡å‹å’Œæ•°æ®åº“ (æ‡’åŠ è½½/å•ä¾‹)
    vector_db = get_vector_db()

    # 2. æ‰§è¡Œæ£€ç´¢
    vector_docs = vector_search(query, vector_db, k=10)
    keyword_docs = bm25_search(query, vector_db, k=10)

    # 3. åˆå¹¶å»é‡
    merged_docs = ensemble_results(vector_docs, keyword_docs)

    # 4. é‡æ’åº
    return rerank_documents(query, merged_docs, top_k=3, score_threshold=RERANK_SCORE_THRESHOLD)


def query_policy(query: str) -> str:
    """
    å¯¹å¤–æ¥å£
    """
    try:
        # ä½¿ç”¨æ‰‹åŠ¨æ··åˆæ£€ç´¢
        docs = get_manual_hybrid_results(query)

        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³æ”¿ç­–ä¿¡æ¯ã€‚"

        results = []
        for i, doc in enumerate(docs):
            # è·å– source (build.py ä¸­æˆ‘ä»¬åªå­˜äº†æ–‡ä»¶å)
            source = doc.metadata.get("source", "æœªçŸ¥æ–‡ä»¶")
            content = doc.page_content.strip()

            entry = f"ã€å‚è€ƒèµ„æ–™ {i + 1}ã€‘\næ¥æº: {source}\nå†…å®¹: {content}"
            results.append(entry)

        return "\n\n".join(results)

    except Exception as e:
        import traceback
        traceback.print_exc()  # æ‰“å°å®Œæ•´æŠ¥é”™å †æ ˆ
        return f"æ£€ç´¢ç³»ç»Ÿé”™è¯¯: {str(e)}"


if __name__ == "__main__":
    print("-" * 30)
    print("ğŸš€ æµ‹è¯•ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆè§¦å‘æ¨¡å‹åŠ è½½ï¼‰:")
    print(query_policy("å·®æ—…ä½å®¿æ ‡å‡†"))
    print("-" * 30)
    print("ğŸš€ æµ‹è¯•ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆåº”ä½¿ç”¨ç¼“å­˜æ¨¡å‹ï¼Œé€Ÿåº¦æ˜¾è‘—æå‡ï¼‰:")
    print(query_policy("äº¤é€šè¡¥è´´æ ‡å‡†"))
